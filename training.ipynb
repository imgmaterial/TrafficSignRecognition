{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset for model training\n",
    "Defining a Dataset class to load the tensor label pairs and dataloader to feed the training in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class GTSRBImageDataset(Dataset):\n",
    "    def __init__(self, label_file, file_dir = \"\", transform = None):\n",
    "        self.df = pd.read_csv(label_file)\n",
    "        self.labels = self.df[\"Labels\"]\n",
    "        self.file_names = self.df[\"Path\"]\n",
    "        self.file_dir = file_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path = os.path.join(self.file_dir, self.file_names[index])\n",
    "        img = cv2.imread(file_path)\n",
    "        label = self.labels[index]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "transform = ToTensor()\n",
    "dataset = GTSRBImageDataset(\"labels.csv\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "train, test = random_split(dataset, [0.7,0.3])\n",
    "training_loader = DataLoader(train, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model\n",
    "Setting up a simple CNN model to test training on the datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "Preparing helper functions for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "from torchmetrics import Accuracy\n",
    "def train_one_epoch(model, train_loader, loss_fn, optimizer, epoch=None, num_classes=10):\n",
    "    model.to(device)\n",
    "    loss_fn.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    loss_train = AverageMeter()\n",
    "    acc_train = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "    acc_train.reset()\n",
    "\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        if epoch is not None:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "        for inputs, targets in tepoch:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train.update(loss.item())\n",
    "            acc_train.update(outputs, targets.int())\n",
    "\n",
    "            tepoch.set_postfix(loss=loss_train.avg)\n",
    "\n",
    "    final_accuracy = acc_train.compute().item()\n",
    "    return model, loss_train.avg, final_accuracy\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "def validation(model, test_loader, loss_fn):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    loss_valid = AverageMeter()\n",
    "    acc_valid = Accuracy(task=\"multiclass\", num_classes=43).to(device)\n",
    "    predictions, labels = [], []\n",
    "    for i, (inputs, targets) in enumerate(test_loader):\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      loss = loss_fn(outputs, targets)\n",
    "\n",
    "      loss_valid.update(loss.item())\n",
    "      acc_valid(outputs, targets.int())\n",
    "      predictions.append(torch.max(outputs.data, 1)[1].cpu().numpy())\n",
    "      labels.append(targets.cpu().numpy())\n",
    "    predictions = np.concatenate(predictions)\n",
    "    labels = np.concatenate(labels)\n",
    "    confusion = metrics.confusion_matrix(labels,predictions)\n",
    "  return loss_valid.avg, acc_valid.compute().item(), confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the sample model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=8192, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=43, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 858/858 [00:14<00:00, 58.19batch/s, loss=1.09]\n",
      "Epoch 1: 100%|██████████| 858/858 [00:09<00:00, 87.73batch/s, loss=0.158]\n",
      "Epoch 2: 100%|██████████| 858/858 [00:09<00:00, 88.09batch/s, loss=0.0709]\n",
      "Epoch 3: 100%|██████████| 858/858 [00:09<00:00, 87.84batch/s, loss=0.0416]\n",
      "Epoch 4: 100%|██████████| 858/858 [00:09<00:00, 87.40batch/s, loss=0.0283]\n",
      "Epoch 5: 100%|██████████| 858/858 [00:09<00:00, 88.00batch/s, loss=0.0202]\n",
      "Epoch 6: 100%|██████████| 858/858 [00:09<00:00, 88.35batch/s, loss=0.0146]\n",
      "Epoch 7: 100%|██████████| 858/858 [00:09<00:00, 87.74batch/s, loss=0.0115]\n",
      "Epoch 8: 100%|██████████| 858/858 [00:09<00:00, 87.88batch/s, loss=0.00939]\n",
      "Epoch 9: 100%|██████████| 858/858 [00:09<00:00, 88.00batch/s, loss=0.00735]\n",
      "Epoch 10: 100%|██████████| 858/858 [00:09<00:00, 87.30batch/s, loss=0.00629]\n",
      "Epoch 11: 100%|██████████| 858/858 [00:09<00:00, 87.53batch/s, loss=0.00583]\n",
      "Epoch 12: 100%|██████████| 858/858 [00:09<00:00, 87.55batch/s, loss=0.00485]\n",
      "Epoch 13: 100%|██████████| 858/858 [00:09<00:00, 87.33batch/s, loss=0.00406]\n",
      "Epoch 14: 100%|██████████| 858/858 [00:09<00:00, 88.22batch/s, loss=0.00366]\n",
      "Epoch 15: 100%|██████████| 858/858 [00:09<00:00, 87.66batch/s, loss=0.00329]\n",
      "Epoch 16: 100%|██████████| 858/858 [00:09<00:00, 87.65batch/s, loss=0.00303]\n",
      "Epoch 17: 100%|██████████| 858/858 [00:09<00:00, 88.24batch/s, loss=0.00281]\n",
      "Epoch 18: 100%|██████████| 858/858 [00:09<00:00, 87.62batch/s, loss=0.0026] \n",
      "Epoch 19: 100%|██████████| 858/858 [00:09<00:00, 86.92batch/s, loss=0.00246]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 0.9999635815620422, Loss 0.0024589568231598636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net = SimpleCNN(43)\n",
    "print(net)\n",
    "net.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(20):\n",
    "    net, loss, acc = train_one_epoch(net, training_loader, criterion, optimizer, num_classes=43, epoch=epoch)\n",
    "print(f\"Model accuracy {acc}, Loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy 0.9961740970611572, test loss 0.016993765021771138\n",
      "[[ 73   0   1   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  1 671   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   2 684   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   1   0 437   0   2   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   1   0 606   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 547   0   1   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 141   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0 416   3   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   2   0   0   0   1   0   0 418   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1 430   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 587   0   0   1   0   0   0   0\n",
      "    0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 406   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 650   2   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0 683   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 217   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0 192   0   0\n",
      "    0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 131   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0 351\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  360   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 113   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0  92   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0 129   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0  77   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0 448   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    2   0   1   0   0   0   0   0 172   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0  77   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0 157   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0  71   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0 149   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   1   0   0   0   0   0   0   0   0   0   0   0 227   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0  64   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 193   0   0\n",
      "    1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 118   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1 343\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  120   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0  62   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "    0   0 582   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0  85   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0 105   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   1   0   0  71   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0  57]]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, confusion = validation(net, test_loader, criterion)\n",
    "print(f\"Test accuracy {test_acc}, test loss {test_loss}\")\n",
    "def print_array(array):\n",
    "  np.set_printoptions(threshold=np.inf)\n",
    "  print(array)\n",
    "  np.set_printoptions(threshold=1000)\n",
    "print_array(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2202155\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
